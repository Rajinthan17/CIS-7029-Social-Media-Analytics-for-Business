{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from torch_geometric.nn import GCNConv,GATConv,SAGEConv\n",
    "import torch_geometric.utils as pyg_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('../facebook_clean_data/company_edges.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 104436], num_nodes=14113, x=[14113, 14113], y=[14113], train_mask=[14113], test_mask=[14113])\n"
     ]
    }
   ],
   "source": [
    "# Create a NetworkX graph from the edge list\n",
    "G = nx.from_pandas_edgelist(df, 'node_1', 'node_2')\n",
    "\n",
    "# If your nodes are not integers, encode them\n",
    "le = LabelEncoder()\n",
    "le.fit(list(G.nodes))\n",
    "df['node_1'] = le.transform(df['node_1'])\n",
    "df['node_2'] = le.transform(df['node_2'])\n",
    "\n",
    "\n",
    "G = nx.from_pandas_edgelist(df, 'node_1', 'node_2')\n",
    "\n",
    "# Convert the NetworkX graph to PyTorch Geometric format\n",
    "data = pyg_utils.from_networkx(G)\n",
    "\n",
    "num_nodes = data.num_nodes\n",
    "data.x = torch.eye(num_nodes)\n",
    "\n",
    "data.y = torch.randint(0, 2, (num_nodes,))\n",
    "\n",
    "data.train_mask = torch.rand(num_nodes) < 0.8\n",
    "data.test_mask = ~data.train_mask\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, data, optimizer):\n",
    "    for epoch in range(200):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch+1} completed.')\n",
    "        print(f'Loss: {loss.item()}')\n",
    "    \n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    _, pred = model(data).max(dim=1)\n",
    "    correct = pred[data.test_mask].eq(data.y[data.test_mask]).sum().item()\n",
    "    acc = correct / data.test_mask.sum().item()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed.\n",
      "Loss: 4.1581902503967285\n",
      "Epoch 2 completed.\n",
      "Loss: 4.107737064361572\n",
      "Epoch 3 completed.\n",
      "Loss: 4.040499210357666\n",
      "Epoch 4 completed.\n",
      "Loss: 3.9582650661468506\n",
      "Epoch 5 completed.\n",
      "Loss: 3.8617279529571533\n",
      "Epoch 6 completed.\n",
      "Loss: 3.7520251274108887\n",
      "Epoch 7 completed.\n",
      "Loss: 3.630073070526123\n",
      "Epoch 8 completed.\n",
      "Loss: 3.4963653087615967\n",
      "Epoch 9 completed.\n",
      "Loss: 3.351057529449463\n",
      "Epoch 10 completed.\n",
      "Loss: 3.1940762996673584\n",
      "Epoch 11 completed.\n",
      "Loss: 3.025426149368286\n",
      "Epoch 12 completed.\n",
      "Loss: 2.845665693283081\n",
      "Epoch 13 completed.\n",
      "Loss: 2.656374454498291\n",
      "Epoch 14 completed.\n",
      "Loss: 2.460500717163086\n",
      "Epoch 15 completed.\n",
      "Loss: 2.262420415878296\n",
      "Epoch 16 completed.\n",
      "Loss: 2.0675203800201416\n",
      "Epoch 17 completed.\n",
      "Loss: 1.8813354969024658\n",
      "Epoch 18 completed.\n",
      "Loss: 1.7085641622543335\n",
      "Epoch 19 completed.\n",
      "Loss: 1.5523715019226074\n",
      "Epoch 20 completed.\n",
      "Loss: 1.414207100868225\n",
      "Epoch 21 completed.\n",
      "Loss: 1.294054388999939\n",
      "Epoch 22 completed.\n",
      "Loss: 1.1908844709396362\n",
      "Epoch 23 completed.\n",
      "Loss: 1.103122353553772\n",
      "Epoch 24 completed.\n",
      "Loss: 1.029015302658081\n",
      "Epoch 25 completed.\n",
      "Loss: 0.9668654203414917\n",
      "Epoch 26 completed.\n",
      "Loss: 0.9151263236999512\n",
      "Epoch 27 completed.\n",
      "Loss: 0.8724057674407959\n",
      "Epoch 28 completed.\n",
      "Loss: 0.8374353647232056\n",
      "Epoch 29 completed.\n",
      "Loss: 0.8090494275093079\n",
      "Epoch 30 completed.\n",
      "Loss: 0.7861860990524292\n",
      "Epoch 31 completed.\n",
      "Loss: 0.7679001092910767\n",
      "Epoch 32 completed.\n",
      "Loss: 0.7533721327781677\n",
      "Epoch 33 completed.\n",
      "Loss: 0.7419052124023438\n",
      "Epoch 34 completed.\n",
      "Loss: 0.7329115271568298\n",
      "Epoch 35 completed.\n",
      "Loss: 0.7258924245834351\n",
      "Epoch 36 completed.\n",
      "Loss: 0.720422625541687\n",
      "Epoch 37 completed.\n",
      "Loss: 0.7161398530006409\n",
      "Epoch 38 completed.\n",
      "Loss: 0.7127417922019958\n",
      "Epoch 39 completed.\n",
      "Loss: 0.7099856734275818\n",
      "Epoch 40 completed.\n",
      "Loss: 0.7076895236968994\n",
      "Epoch 41 completed.\n",
      "Loss: 0.705729603767395\n",
      "Epoch 42 completed.\n",
      "Loss: 0.7040323615074158\n",
      "Epoch 43 completed.\n",
      "Loss: 0.7025620341300964\n",
      "Epoch 44 completed.\n",
      "Loss: 0.7013047933578491\n",
      "Epoch 45 completed.\n",
      "Loss: 0.7002529501914978\n",
      "Epoch 46 completed.\n",
      "Loss: 0.6993935704231262\n",
      "Epoch 47 completed.\n",
      "Loss: 0.6987019181251526\n",
      "Epoch 48 completed.\n",
      "Loss: 0.6981427073478699\n",
      "Epoch 49 completed.\n",
      "Loss: 0.6976749897003174\n",
      "Epoch 50 completed.\n",
      "Loss: 0.6972609162330627\n",
      "Epoch 51 completed.\n",
      "Loss: 0.6968739032745361\n",
      "Epoch 52 completed.\n",
      "Loss: 0.6965022087097168\n",
      "Epoch 53 completed.\n",
      "Loss: 0.6961487531661987\n",
      "Epoch 54 completed.\n",
      "Loss: 0.69582599401474\n",
      "Epoch 55 completed.\n",
      "Loss: 0.6955491900444031\n",
      "Epoch 56 completed.\n",
      "Loss: 0.6953290104866028\n",
      "Epoch 57 completed.\n",
      "Loss: 0.6951667666435242\n",
      "Epoch 58 completed.\n",
      "Loss: 0.6950539350509644\n",
      "Epoch 59 completed.\n",
      "Loss: 0.6949741244316101\n",
      "Epoch 60 completed.\n",
      "Loss: 0.6949086785316467\n",
      "Epoch 61 completed.\n",
      "Loss: 0.6948421597480774\n",
      "Epoch 62 completed.\n",
      "Loss: 0.694766104221344\n",
      "Epoch 63 completed.\n",
      "Loss: 0.6946804523468018\n",
      "Epoch 64 completed.\n",
      "Loss: 0.6945915818214417\n",
      "Epoch 65 completed.\n",
      "Loss: 0.6945091485977173\n",
      "Epoch 66 completed.\n",
      "Loss: 0.6944418549537659\n",
      "Epoch 67 completed.\n",
      "Loss: 0.6943941712379456\n",
      "Epoch 68 completed.\n",
      "Loss: 0.694365382194519\n",
      "Epoch 69 completed.\n",
      "Loss: 0.6943511962890625\n",
      "Epoch 70 completed.\n",
      "Loss: 0.6943453550338745\n",
      "Epoch 71 completed.\n",
      "Loss: 0.694342315196991\n",
      "Epoch 72 completed.\n",
      "Loss: 0.6943391561508179\n",
      "Epoch 73 completed.\n",
      "Loss: 0.6943356394767761\n",
      "Epoch 74 completed.\n",
      "Loss: 0.6943337917327881\n",
      "Epoch 75 completed.\n",
      "Loss: 0.6943356990814209\n",
      "Epoch 76 completed.\n",
      "Loss: 0.6943429112434387\n",
      "Epoch 77 completed.\n",
      "Loss: 0.6943551898002625\n",
      "Epoch 78 completed.\n",
      "Loss: 0.6943711638450623\n",
      "Epoch 79 completed.\n",
      "Loss: 0.6943885684013367\n",
      "Epoch 80 completed.\n",
      "Loss: 0.6944056153297424\n",
      "Epoch 81 completed.\n",
      "Loss: 0.694421648979187\n",
      "Epoch 82 completed.\n",
      "Loss: 0.6944373250007629\n",
      "Epoch 83 completed.\n",
      "Loss: 0.694453775882721\n",
      "Epoch 84 completed.\n",
      "Loss: 0.6944727897644043\n",
      "Epoch 85 completed.\n",
      "Loss: 0.6944951415061951\n",
      "Epoch 86 completed.\n",
      "Loss: 0.6945207715034485\n",
      "Epoch 87 completed.\n",
      "Loss: 0.6945485472679138\n",
      "Epoch 88 completed.\n",
      "Loss: 0.6945767402648926\n",
      "Epoch 89 completed.\n",
      "Loss: 0.6946038007736206\n",
      "Epoch 90 completed.\n",
      "Loss: 0.6946286559104919\n",
      "Epoch 91 completed.\n",
      "Loss: 0.6946508288383484\n",
      "Epoch 92 completed.\n",
      "Loss: 0.6946704387664795\n",
      "Epoch 93 completed.\n",
      "Loss: 0.6946873664855957\n",
      "Epoch 94 completed.\n",
      "Loss: 0.6947013735771179\n",
      "Epoch 95 completed.\n",
      "Loss: 0.6947110891342163\n",
      "Epoch 96 completed.\n",
      "Loss: 0.6947147846221924\n",
      "Epoch 97 completed.\n",
      "Loss: 0.6947099566459656\n",
      "Epoch 98 completed.\n",
      "Loss: 0.6946946382522583\n",
      "Epoch 99 completed.\n",
      "Loss: 0.6946675777435303\n",
      "Epoch 100 completed.\n",
      "Loss: 0.6946296095848083\n",
      "Epoch 101 completed.\n",
      "Loss: 0.6945819854736328\n",
      "Epoch 102 completed.\n",
      "Loss: 0.6945249438285828\n",
      "Epoch 103 completed.\n",
      "Loss: 0.6944510340690613\n",
      "Epoch 104 completed.\n",
      "Loss: 0.6943574547767639\n",
      "Epoch 105 completed.\n",
      "Loss: 0.6942440867424011\n",
      "Epoch 106 completed.\n",
      "Loss: 0.6941156983375549\n",
      "Epoch 107 completed.\n",
      "Loss: 0.6939769983291626\n",
      "Epoch 108 completed.\n",
      "Loss: 0.6938284039497375\n",
      "Epoch 109 completed.\n",
      "Loss: 0.6936658620834351\n",
      "Epoch 110 completed.\n",
      "Loss: 0.6934894919395447\n",
      "Epoch 111 completed.\n",
      "Loss: 0.6932971477508545\n",
      "Epoch 112 completed.\n",
      "Loss: 0.693089485168457\n",
      "Epoch 113 completed.\n",
      "Loss: 0.6928677558898926\n",
      "Epoch 114 completed.\n",
      "Loss: 0.6926283240318298\n",
      "Epoch 115 completed.\n",
      "Loss: 0.6923710703849792\n",
      "Epoch 116 completed.\n",
      "Loss: 0.6921025514602661\n",
      "Epoch 117 completed.\n",
      "Loss: 0.6918218731880188\n",
      "Epoch 118 completed.\n",
      "Loss: 0.6915334463119507\n",
      "Epoch 119 completed.\n",
      "Loss: 0.691224217414856\n",
      "Epoch 120 completed.\n",
      "Loss: 0.6909133791923523\n",
      "Epoch 121 completed.\n",
      "Loss: 0.6905832290649414\n",
      "Epoch 122 completed.\n",
      "Loss: 0.6902331709861755\n",
      "Epoch 123 completed.\n",
      "Loss: 0.6898688077926636\n",
      "Epoch 124 completed.\n",
      "Loss: 0.6894900798797607\n",
      "Epoch 125 completed.\n",
      "Loss: 0.6890966892242432\n",
      "Epoch 126 completed.\n",
      "Loss: 0.6886950731277466\n",
      "Epoch 127 completed.\n",
      "Loss: 0.6882853507995605\n",
      "Epoch 128 completed.\n",
      "Loss: 0.6878638863563538\n",
      "Epoch 129 completed.\n",
      "Loss: 0.6874437928199768\n",
      "Epoch 130 completed.\n",
      "Loss: 0.6870080828666687\n",
      "Epoch 131 completed.\n",
      "Loss: 0.686561107635498\n",
      "Epoch 132 completed.\n",
      "Loss: 0.6860985159873962\n",
      "Epoch 133 completed.\n",
      "Loss: 0.6856228113174438\n",
      "Epoch 134 completed.\n",
      "Loss: 0.6851359605789185\n",
      "Epoch 135 completed.\n",
      "Loss: 0.6846409440040588\n",
      "Epoch 136 completed.\n",
      "Loss: 0.6841467022895813\n",
      "Epoch 137 completed.\n",
      "Loss: 0.683643102645874\n",
      "Epoch 138 completed.\n",
      "Loss: 0.6831487417221069\n",
      "Epoch 139 completed.\n",
      "Loss: 0.6826282739639282\n",
      "Epoch 140 completed.\n",
      "Loss: 0.6821028590202332\n",
      "Epoch 141 completed.\n",
      "Loss: 0.681569516658783\n",
      "Epoch 142 completed.\n",
      "Loss: 0.6810193061828613\n",
      "Epoch 143 completed.\n",
      "Loss: 0.6804711818695068\n",
      "Epoch 144 completed.\n",
      "Loss: 0.6799283623695374\n",
      "Epoch 145 completed.\n",
      "Loss: 0.6793718338012695\n",
      "Epoch 146 completed.\n",
      "Loss: 0.6788053512573242\n",
      "Epoch 147 completed.\n",
      "Loss: 0.6782404780387878\n",
      "Epoch 148 completed.\n",
      "Loss: 0.6776587963104248\n",
      "Epoch 149 completed.\n",
      "Loss: 0.6770832538604736\n",
      "Epoch 150 completed.\n",
      "Loss: 0.6765150427818298\n",
      "Epoch 151 completed.\n",
      "Loss: 0.6759316325187683\n",
      "Epoch 152 completed.\n",
      "Loss: 0.6753491163253784\n",
      "Epoch 153 completed.\n",
      "Loss: 0.6747599244117737\n",
      "Epoch 154 completed.\n",
      "Loss: 0.6741606593132019\n",
      "Epoch 155 completed.\n",
      "Loss: 0.6735628843307495\n",
      "Epoch 156 completed.\n",
      "Loss: 0.6729593873023987\n",
      "Epoch 157 completed.\n",
      "Loss: 0.6723529696464539\n",
      "Epoch 158 completed.\n",
      "Loss: 0.6717513203620911\n",
      "Epoch 159 completed.\n",
      "Loss: 0.6711432933807373\n",
      "Epoch 160 completed.\n",
      "Loss: 0.6705374717712402\n",
      "Epoch 161 completed.\n",
      "Loss: 0.669935941696167\n",
      "Epoch 162 completed.\n",
      "Loss: 0.6693283915519714\n",
      "Epoch 163 completed.\n",
      "Loss: 0.6687275171279907\n",
      "Epoch 164 completed.\n",
      "Loss: 0.6681122183799744\n",
      "Epoch 165 completed.\n",
      "Loss: 0.6675018072128296\n",
      "Epoch 166 completed.\n",
      "Loss: 0.6668917536735535\n",
      "Epoch 167 completed.\n",
      "Loss: 0.666269063949585\n",
      "Epoch 168 completed.\n",
      "Loss: 0.665651798248291\n",
      "Epoch 169 completed.\n",
      "Loss: 0.6650402545928955\n",
      "Epoch 170 completed.\n",
      "Loss: 0.6644260883331299\n",
      "Epoch 171 completed.\n",
      "Loss: 0.6638126969337463\n",
      "Epoch 172 completed.\n",
      "Loss: 0.6631938815116882\n",
      "Epoch 173 completed.\n",
      "Loss: 0.6625745296478271\n",
      "Epoch 174 completed.\n",
      "Loss: 0.661964476108551\n",
      "Epoch 175 completed.\n",
      "Loss: 0.6613503098487854\n",
      "Epoch 176 completed.\n",
      "Loss: 0.660735547542572\n",
      "Epoch 177 completed.\n",
      "Loss: 0.6601247787475586\n",
      "Epoch 178 completed.\n",
      "Loss: 0.6595174670219421\n",
      "Epoch 179 completed.\n",
      "Loss: 0.658916175365448\n",
      "Epoch 180 completed.\n",
      "Loss: 0.6583116054534912\n",
      "Epoch 181 completed.\n",
      "Loss: 0.6577085256576538\n",
      "Epoch 182 completed.\n",
      "Loss: 0.6571028828620911\n",
      "Epoch 183 completed.\n",
      "Loss: 0.6564955115318298\n",
      "Epoch 184 completed.\n",
      "Loss: 0.6558865904808044\n",
      "Epoch 185 completed.\n",
      "Loss: 0.655282199382782\n",
      "Epoch 186 completed.\n",
      "Loss: 0.6546791195869446\n",
      "Epoch 187 completed.\n",
      "Loss: 0.6540836691856384\n",
      "Epoch 188 completed.\n",
      "Loss: 0.6534906029701233\n",
      "Epoch 189 completed.\n",
      "Loss: 0.6529058218002319\n",
      "Epoch 190 completed.\n",
      "Loss: 0.6523112058639526\n",
      "Epoch 191 completed.\n",
      "Loss: 0.6517205834388733\n",
      "Epoch 192 completed.\n",
      "Loss: 0.6511229872703552\n",
      "Epoch 193 completed.\n",
      "Loss: 0.6505433320999146\n",
      "Epoch 194 completed.\n",
      "Loss: 0.6499742865562439\n",
      "Epoch 195 completed.\n",
      "Loss: 0.649384617805481\n",
      "Epoch 196 completed.\n",
      "Loss: 0.648801863193512\n",
      "Epoch 197 completed.\n",
      "Loss: 0.6482241153717041\n",
      "Epoch 198 completed.\n",
      "Loss: 0.6476399898529053\n",
      "Epoch 199 completed.\n",
      "Loss: 0.6470588445663452\n",
      "Epoch 200 completed.\n",
      "Loss: 0.6464834213256836\n",
      "GCN Accuracy: 0.5009\n",
      "Epoch 1 completed.\n",
      "Loss: 4.157429218292236\n",
      "Epoch 2 completed.\n",
      "Loss: 4.095411777496338\n",
      "Epoch 3 completed.\n",
      "Loss: 4.0148091316223145\n",
      "Epoch 4 completed.\n",
      "Loss: 3.9178366661071777\n",
      "Epoch 5 completed.\n",
      "Loss: 3.805250883102417\n",
      "Epoch 6 completed.\n",
      "Loss: 3.678056240081787\n",
      "Epoch 7 completed.\n",
      "Loss: 3.536956310272217\n",
      "Epoch 8 completed.\n",
      "Loss: 3.382096529006958\n",
      "Epoch 9 completed.\n",
      "Loss: 3.213458776473999\n",
      "Epoch 10 completed.\n",
      "Loss: 3.0305731296539307\n",
      "Epoch 11 completed.\n",
      "Loss: 2.832925796508789\n",
      "Epoch 12 completed.\n",
      "Loss: 2.620741605758667\n",
      "Epoch 13 completed.\n",
      "Loss: 2.395362138748169\n",
      "Epoch 14 completed.\n",
      "Loss: 2.159799575805664\n",
      "Epoch 15 completed.\n",
      "Loss: 1.9191246032714844\n",
      "Epoch 16 completed.\n",
      "Loss: 1.6805737018585205\n",
      "Epoch 17 completed.\n",
      "Loss: 1.4535584449768066\n",
      "Epoch 18 completed.\n",
      "Loss: 1.2494418621063232\n",
      "Epoch 19 completed.\n",
      "Loss: 1.0796995162963867\n",
      "Epoch 20 completed.\n",
      "Loss: 0.9512888789176941\n",
      "Epoch 21 completed.\n",
      "Loss: 0.8626657724380493\n",
      "Epoch 22 completed.\n",
      "Loss: 0.8053338527679443\n",
      "Epoch 23 completed.\n",
      "Loss: 0.7690588235855103\n",
      "Epoch 24 completed.\n",
      "Loss: 0.7457001209259033\n",
      "Epoch 25 completed.\n",
      "Loss: 0.7301893830299377\n",
      "Epoch 26 completed.\n",
      "Loss: 0.7197325229644775\n",
      "Epoch 27 completed.\n",
      "Loss: 0.7128005623817444\n",
      "Epoch 28 completed.\n",
      "Loss: 0.70838862657547\n",
      "Epoch 29 completed.\n",
      "Loss: 0.7055848240852356\n",
      "Epoch 30 completed.\n",
      "Loss: 0.7035378217697144\n",
      "Epoch 31 completed.\n",
      "Loss: 0.7016609907150269\n",
      "Epoch 32 completed.\n",
      "Loss: 0.6997640132904053\n",
      "Epoch 33 completed.\n",
      "Loss: 0.6979470252990723\n",
      "Epoch 34 completed.\n",
      "Loss: 0.6964364051818848\n",
      "Epoch 35 completed.\n",
      "Loss: 0.6954126954078674\n",
      "Epoch 36 completed.\n",
      "Loss: 0.6948862671852112\n",
      "Epoch 37 completed.\n",
      "Loss: 0.6946661472320557\n",
      "Epoch 38 completed.\n",
      "Loss: 0.6944743990898132\n",
      "Epoch 39 completed.\n",
      "Loss: 0.6941298842430115\n",
      "Epoch 40 completed.\n",
      "Loss: 0.6936323046684265\n",
      "Epoch 41 completed.\n",
      "Loss: 0.6931082010269165\n",
      "Epoch 42 completed.\n",
      "Loss: 0.6926956176757812\n",
      "Epoch 43 completed.\n",
      "Loss: 0.6924558877944946\n",
      "Epoch 44 completed.\n",
      "Loss: 0.692349374294281\n",
      "Epoch 45 completed.\n",
      "Loss: 0.6922807097434998\n",
      "Epoch 46 completed.\n",
      "Loss: 0.6921572685241699\n",
      "Epoch 47 completed.\n",
      "Loss: 0.6919485330581665\n",
      "Epoch 48 completed.\n",
      "Loss: 0.691688060760498\n",
      "Epoch 49 completed.\n",
      "Loss: 0.6914385557174683\n",
      "Epoch 50 completed.\n",
      "Loss: 0.691251814365387\n",
      "Epoch 51 completed.\n",
      "Loss: 0.6911349296569824\n",
      "Epoch 52 completed.\n",
      "Loss: 0.691050112247467\n",
      "Epoch 53 completed.\n",
      "Loss: 0.6909460425376892\n",
      "Epoch 54 completed.\n",
      "Loss: 0.6907927989959717\n",
      "Epoch 55 completed.\n",
      "Loss: 0.6905987858772278\n",
      "Epoch 56 completed.\n",
      "Loss: 0.6903952360153198\n",
      "Epoch 57 completed.\n",
      "Loss: 0.6902129650115967\n",
      "Epoch 58 completed.\n",
      "Loss: 0.6900571584701538\n",
      "Epoch 59 completed.\n",
      "Loss: 0.6899048089981079\n",
      "Epoch 60 completed.\n",
      "Loss: 0.6897251009941101\n",
      "Epoch 61 completed.\n",
      "Loss: 0.689506471157074\n",
      "Epoch 62 completed.\n",
      "Loss: 0.6892598867416382\n",
      "Epoch 63 completed.\n",
      "Loss: 0.6890029311180115\n",
      "Epoch 64 completed.\n",
      "Loss: 0.6887441277503967\n",
      "Epoch 65 completed.\n",
      "Loss: 0.6884759068489075\n",
      "Epoch 66 completed.\n",
      "Loss: 0.6881844997406006\n",
      "Epoch 67 completed.\n",
      "Loss: 0.6878591179847717\n",
      "Epoch 68 completed.\n",
      "Loss: 0.6874992251396179\n",
      "Epoch 69 completed.\n",
      "Loss: 0.6871117353439331\n",
      "Epoch 70 completed.\n",
      "Loss: 0.6867010593414307\n",
      "Epoch 71 completed.\n",
      "Loss: 0.6862607598304749\n",
      "Epoch 72 completed.\n",
      "Loss: 0.6857807636260986\n",
      "Epoch 73 completed.\n",
      "Loss: 0.6852564215660095\n",
      "Epoch 74 completed.\n",
      "Loss: 0.6846904158592224\n",
      "Epoch 75 completed.\n",
      "Loss: 0.6840879917144775\n",
      "Epoch 76 completed.\n",
      "Loss: 0.6834492683410645\n",
      "Epoch 77 completed.\n",
      "Loss: 0.6827676892280579\n",
      "Epoch 78 completed.\n",
      "Loss: 0.6820390224456787\n",
      "Epoch 79 completed.\n",
      "Loss: 0.6812631487846375\n",
      "Epoch 80 completed.\n",
      "Loss: 0.6804423928260803\n",
      "Epoch 81 completed.\n",
      "Loss: 0.6795706748962402\n",
      "Epoch 82 completed.\n",
      "Loss: 0.6786410212516785\n",
      "Epoch 83 completed.\n",
      "Loss: 0.6776531338691711\n",
      "Epoch 84 completed.\n",
      "Loss: 0.6766049265861511\n",
      "Epoch 85 completed.\n",
      "Loss: 0.6754937767982483\n",
      "Epoch 86 completed.\n",
      "Loss: 0.6743135452270508\n",
      "Epoch 87 completed.\n",
      "Loss: 0.6730642318725586\n",
      "Epoch 88 completed.\n",
      "Loss: 0.6717462539672852\n",
      "Epoch 89 completed.\n",
      "Loss: 0.6703737378120422\n",
      "Epoch 90 completed.\n",
      "Loss: 0.6689612865447998\n",
      "Epoch 91 completed.\n",
      "Loss: 0.667489230632782\n",
      "Epoch 92 completed.\n",
      "Loss: 0.6659547686576843\n",
      "Epoch 93 completed.\n",
      "Loss: 0.6643626689910889\n",
      "Epoch 94 completed.\n",
      "Loss: 0.6627065539360046\n",
      "Epoch 95 completed.\n",
      "Loss: 0.6609823107719421\n",
      "Epoch 96 completed.\n",
      "Loss: 0.6591922640800476\n",
      "Epoch 97 completed.\n",
      "Loss: 0.6573291420936584\n",
      "Epoch 98 completed.\n",
      "Loss: 0.6553842425346375\n",
      "Epoch 99 completed.\n",
      "Loss: 0.6533673405647278\n",
      "Epoch 100 completed.\n",
      "Loss: 0.6512776613235474\n",
      "Epoch 101 completed.\n",
      "Loss: 0.6491087675094604\n",
      "Epoch 102 completed.\n",
      "Loss: 0.646865963935852\n",
      "Epoch 103 completed.\n",
      "Loss: 0.6445413827896118\n",
      "Epoch 104 completed.\n",
      "Loss: 0.6421294808387756\n",
      "Epoch 105 completed.\n",
      "Loss: 0.639604389667511\n",
      "Epoch 106 completed.\n",
      "Loss: 0.6369205713272095\n",
      "Epoch 107 completed.\n",
      "Loss: 0.6341270208358765\n",
      "Epoch 108 completed.\n",
      "Loss: 0.6312083005905151\n",
      "Epoch 109 completed.\n",
      "Loss: 0.6281517744064331\n",
      "Epoch 110 completed.\n",
      "Loss: 0.6250221729278564\n",
      "Epoch 111 completed.\n",
      "Loss: 0.6218155026435852\n",
      "Epoch 112 completed.\n",
      "Loss: 0.6184984445571899\n",
      "Epoch 113 completed.\n",
      "Loss: 0.6150255799293518\n",
      "Epoch 114 completed.\n",
      "Loss: 0.6114110350608826\n",
      "Epoch 115 completed.\n",
      "Loss: 0.6076982021331787\n",
      "Epoch 116 completed.\n",
      "Loss: 0.6037158966064453\n",
      "Epoch 117 completed.\n",
      "Loss: 0.5995438694953918\n",
      "Epoch 118 completed.\n",
      "Loss: 0.5951681137084961\n",
      "Epoch 119 completed.\n",
      "Loss: 0.5905998349189758\n",
      "Epoch 120 completed.\n",
      "Loss: 0.585883617401123\n",
      "Epoch 121 completed.\n",
      "Loss: 0.5810325145721436\n",
      "Epoch 122 completed.\n",
      "Loss: 0.5759908556938171\n",
      "Epoch 123 completed.\n",
      "Loss: 0.5706065893173218\n",
      "Epoch 124 completed.\n",
      "Loss: 0.5649142265319824\n",
      "Epoch 125 completed.\n",
      "Loss: 0.5590280294418335\n",
      "Epoch 126 completed.\n",
      "Loss: 0.5530563592910767\n",
      "Epoch 127 completed.\n",
      "Loss: 0.5468194484710693\n",
      "Epoch 128 completed.\n",
      "Loss: 0.5404999256134033\n",
      "Epoch 129 completed.\n",
      "Loss: 0.5339407324790955\n",
      "Epoch 130 completed.\n",
      "Loss: 0.5271091461181641\n",
      "Epoch 131 completed.\n",
      "Loss: 0.5203571319580078\n",
      "Epoch 132 completed.\n",
      "Loss: 0.5140579342842102\n",
      "Epoch 133 completed.\n",
      "Loss: 0.5067962408065796\n",
      "Epoch 134 completed.\n",
      "Loss: 0.4986889064311981\n",
      "Epoch 135 completed.\n",
      "Loss: 0.4922895133495331\n",
      "Epoch 136 completed.\n",
      "Loss: 0.4853758215904236\n",
      "Epoch 137 completed.\n",
      "Loss: 0.4773246943950653\n",
      "Epoch 138 completed.\n",
      "Loss: 0.46860471367836\n",
      "Epoch 139 completed.\n",
      "Loss: 0.4609232246875763\n",
      "Epoch 140 completed.\n",
      "Loss: 0.45331257581710815\n",
      "Epoch 141 completed.\n",
      "Loss: 0.4456782042980194\n",
      "Epoch 142 completed.\n",
      "Loss: 0.43859967589378357\n",
      "Epoch 143 completed.\n",
      "Loss: 0.43178290128707886\n",
      "Epoch 144 completed.\n",
      "Loss: 0.4243395924568176\n",
      "Epoch 145 completed.\n",
      "Loss: 0.4169915020465851\n",
      "Epoch 146 completed.\n",
      "Loss: 0.40927502512931824\n",
      "Epoch 147 completed.\n",
      "Loss: 0.40298041701316833\n",
      "Epoch 148 completed.\n",
      "Loss: 0.395800918340683\n",
      "Epoch 149 completed.\n",
      "Loss: 0.3893287479877472\n",
      "Epoch 150 completed.\n",
      "Loss: 0.38263070583343506\n",
      "Epoch 151 completed.\n",
      "Loss: 0.3768738806247711\n",
      "Epoch 152 completed.\n",
      "Loss: 0.37511417269706726\n",
      "Epoch 153 completed.\n",
      "Loss: 0.38422784209251404\n",
      "Epoch 154 completed.\n",
      "Loss: 0.37908869981765747\n",
      "Epoch 155 completed.\n",
      "Loss: 0.36464813351631165\n",
      "Epoch 156 completed.\n",
      "Loss: 0.3647237718105316\n",
      "Epoch 157 completed.\n",
      "Loss: 0.3574681580066681\n",
      "Epoch 158 completed.\n",
      "Loss: 0.35260987281799316\n",
      "Epoch 159 completed.\n",
      "Loss: 0.34802719950675964\n",
      "Epoch 160 completed.\n",
      "Loss: 0.3427743911743164\n",
      "Epoch 161 completed.\n",
      "Loss: 0.3375076949596405\n",
      "Epoch 162 completed.\n",
      "Loss: 0.3333560824394226\n",
      "Epoch 163 completed.\n",
      "Loss: 0.32933318614959717\n",
      "Epoch 164 completed.\n",
      "Loss: 0.3273168206214905\n",
      "Epoch 165 completed.\n",
      "Loss: 0.3307174742221832\n",
      "Epoch 166 completed.\n",
      "Loss: 0.3359096050262451\n",
      "Epoch 167 completed.\n",
      "Loss: 0.3275727331638336\n",
      "Epoch 168 completed.\n",
      "Loss: 0.3204144537448883\n",
      "Epoch 169 completed.\n",
      "Loss: 0.3189041316509247\n",
      "Epoch 170 completed.\n",
      "Loss: 0.3139756917953491\n",
      "Epoch 171 completed.\n",
      "Loss: 0.3099372684955597\n",
      "Epoch 172 completed.\n",
      "Loss: 0.3070894181728363\n",
      "Epoch 173 completed.\n",
      "Loss: 0.30412521958351135\n",
      "Epoch 174 completed.\n",
      "Loss: 0.3001526892185211\n",
      "Epoch 175 completed.\n",
      "Loss: 0.29628488421440125\n",
      "Epoch 176 completed.\n",
      "Loss: 0.29304003715515137\n",
      "Epoch 177 completed.\n",
      "Loss: 0.2900826930999756\n",
      "Epoch 178 completed.\n",
      "Loss: 0.2885521352291107\n",
      "Epoch 179 completed.\n",
      "Loss: 0.28758180141448975\n",
      "Epoch 180 completed.\n",
      "Loss: 0.29479244351387024\n",
      "Epoch 181 completed.\n",
      "Loss: 0.3046143651008606\n",
      "Epoch 182 completed.\n",
      "Loss: 0.30732274055480957\n",
      "Epoch 183 completed.\n",
      "Loss: 0.2946229577064514\n",
      "Epoch 184 completed.\n",
      "Loss: 0.29288792610168457\n",
      "Epoch 185 completed.\n",
      "Loss: 0.2895065248012543\n",
      "Epoch 186 completed.\n",
      "Loss: 0.28550875186920166\n",
      "Epoch 187 completed.\n",
      "Loss: 0.28392887115478516\n",
      "Epoch 188 completed.\n",
      "Loss: 0.2811248004436493\n",
      "Epoch 189 completed.\n",
      "Loss: 0.27804338932037354\n",
      "Epoch 190 completed.\n",
      "Loss: 0.27454057335853577\n",
      "Epoch 191 completed.\n",
      "Loss: 0.2721334993839264\n",
      "Epoch 192 completed.\n",
      "Loss: 0.2699969708919525\n",
      "Epoch 193 completed.\n",
      "Loss: 0.26683133840560913\n",
      "Epoch 194 completed.\n",
      "Loss: 0.264652281999588\n",
      "Epoch 195 completed.\n",
      "Loss: 0.2625572085380554\n",
      "Epoch 196 completed.\n",
      "Loss: 0.2618163526058197\n",
      "Epoch 197 completed.\n",
      "Loss: 0.2600701153278351\n",
      "Epoch 198 completed.\n",
      "Loss: 0.26128318905830383\n",
      "Epoch 199 completed.\n",
      "Loss: 0.26223304867744446\n",
      "Epoch 200 completed.\n",
      "Loss: 0.2611047029495239\n",
      "GAT Accuracy: 0.5085\n",
      "Epoch 1 completed.\n",
      "Loss: 4.131718635559082\n",
      "Epoch 2 completed.\n",
      "Loss: 4.021304130554199\n",
      "Epoch 3 completed.\n",
      "Loss: 3.8594322204589844\n",
      "Epoch 4 completed.\n",
      "Loss: 3.6434154510498047\n",
      "Epoch 5 completed.\n",
      "Loss: 3.3723151683807373\n",
      "Epoch 6 completed.\n",
      "Loss: 3.0453600883483887\n",
      "Epoch 7 completed.\n",
      "Loss: 2.668666124343872\n",
      "Epoch 8 completed.\n",
      "Loss: 2.259331703186035\n",
      "Epoch 9 completed.\n",
      "Loss: 1.8489493131637573\n",
      "Epoch 10 completed.\n",
      "Loss: 1.482271432876587\n",
      "Epoch 11 completed.\n",
      "Loss: 1.197563886642456\n",
      "Epoch 12 completed.\n",
      "Loss: 1.0034629106521606\n",
      "Epoch 13 completed.\n",
      "Loss: 0.8822954893112183\n",
      "Epoch 14 completed.\n",
      "Loss: 0.8092119693756104\n",
      "Epoch 15 completed.\n",
      "Loss: 0.7641769051551819\n",
      "Epoch 16 completed.\n",
      "Loss: 0.7343078851699829\n",
      "Epoch 17 completed.\n",
      "Loss: 0.7124030590057373\n",
      "Epoch 18 completed.\n",
      "Loss: 0.6948081254959106\n",
      "Epoch 19 completed.\n",
      "Loss: 0.6799810528755188\n",
      "Epoch 20 completed.\n",
      "Loss: 0.6673157215118408\n",
      "Epoch 21 completed.\n",
      "Loss: 0.656440258026123\n",
      "Epoch 22 completed.\n",
      "Loss: 0.6471163034439087\n",
      "Epoch 23 completed.\n",
      "Loss: 0.639036238193512\n",
      "Epoch 24 completed.\n",
      "Loss: 0.6318579912185669\n",
      "Epoch 25 completed.\n",
      "Loss: 0.6252853870391846\n",
      "Epoch 26 completed.\n",
      "Loss: 0.619042694568634\n",
      "Epoch 27 completed.\n",
      "Loss: 0.612843930721283\n",
      "Epoch 28 completed.\n",
      "Loss: 0.6064133644104004\n",
      "Epoch 29 completed.\n",
      "Loss: 0.5994977355003357\n",
      "Epoch 30 completed.\n",
      "Loss: 0.591913104057312\n",
      "Epoch 31 completed.\n",
      "Loss: 0.583561897277832\n",
      "Epoch 32 completed.\n",
      "Loss: 0.574446439743042\n",
      "Epoch 33 completed.\n",
      "Loss: 0.5646687150001526\n",
      "Epoch 34 completed.\n",
      "Loss: 0.5543938875198364\n",
      "Epoch 35 completed.\n",
      "Loss: 0.5438172817230225\n",
      "Epoch 36 completed.\n",
      "Loss: 0.5331321358680725\n",
      "Epoch 37 completed.\n",
      "Loss: 0.5225156545639038\n",
      "Epoch 38 completed.\n",
      "Loss: 0.5120967030525208\n",
      "Epoch 39 completed.\n",
      "Loss: 0.5019404888153076\n",
      "Epoch 40 completed.\n",
      "Loss: 0.4920519292354584\n",
      "Epoch 41 completed.\n",
      "Loss: 0.482390433549881\n",
      "Epoch 42 completed.\n",
      "Loss: 0.4728970229625702\n",
      "Epoch 43 completed.\n",
      "Loss: 0.463508665561676\n",
      "Epoch 44 completed.\n",
      "Loss: 0.45418596267700195\n",
      "Epoch 45 completed.\n",
      "Loss: 0.44490155577659607\n",
      "Epoch 46 completed.\n",
      "Loss: 0.43565770983695984\n",
      "Epoch 47 completed.\n",
      "Loss: 0.42647528648376465\n",
      "Epoch 48 completed.\n",
      "Loss: 0.41739562153816223\n",
      "Epoch 49 completed.\n",
      "Loss: 0.4084652066230774\n",
      "Epoch 50 completed.\n",
      "Loss: 0.39972442388534546\n",
      "Epoch 51 completed.\n",
      "Loss: 0.3911912441253662\n",
      "Epoch 52 completed.\n",
      "Loss: 0.3828618824481964\n",
      "Epoch 53 completed.\n",
      "Loss: 0.3747308552265167\n",
      "Epoch 54 completed.\n",
      "Loss: 0.36678439378738403\n",
      "Epoch 55 completed.\n",
      "Loss: 0.3590148687362671\n",
      "Epoch 56 completed.\n",
      "Loss: 0.35142576694488525\n",
      "Epoch 57 completed.\n",
      "Loss: 0.34404417872428894\n",
      "Epoch 58 completed.\n",
      "Loss: 0.3368942439556122\n",
      "Epoch 59 completed.\n",
      "Loss: 0.3299936354160309\n",
      "Epoch 60 completed.\n",
      "Loss: 0.32334691286087036\n",
      "Epoch 61 completed.\n",
      "Loss: 0.31693902611732483\n",
      "Epoch 62 completed.\n",
      "Loss: 0.3107595145702362\n",
      "Epoch 63 completed.\n",
      "Loss: 0.3047851324081421\n",
      "Epoch 64 completed.\n",
      "Loss: 0.2990017235279083\n",
      "Epoch 65 completed.\n",
      "Loss: 0.2933986186981201\n",
      "Epoch 66 completed.\n",
      "Loss: 0.2879716455936432\n",
      "Epoch 67 completed.\n",
      "Loss: 0.28272026777267456\n",
      "Epoch 68 completed.\n",
      "Loss: 0.2776396572589874\n",
      "Epoch 69 completed.\n",
      "Loss: 0.2727237343788147\n",
      "Epoch 70 completed.\n",
      "Loss: 0.26796823740005493\n",
      "Epoch 71 completed.\n",
      "Loss: 0.2633645832538605\n",
      "Epoch 72 completed.\n",
      "Loss: 0.2589015066623688\n",
      "Epoch 73 completed.\n",
      "Loss: 0.25458160042762756\n",
      "Epoch 74 completed.\n",
      "Loss: 0.250398725271225\n",
      "Epoch 75 completed.\n",
      "Loss: 0.24635004997253418\n",
      "Epoch 76 completed.\n",
      "Loss: 0.24243482947349548\n",
      "Epoch 77 completed.\n",
      "Loss: 0.23865285515785217\n",
      "Epoch 78 completed.\n",
      "Loss: 0.23500660061836243\n",
      "Epoch 79 completed.\n",
      "Loss: 0.23148828744888306\n",
      "Epoch 80 completed.\n",
      "Loss: 0.22808830440044403\n",
      "Epoch 81 completed.\n",
      "Loss: 0.22479677200317383\n",
      "Epoch 82 completed.\n",
      "Loss: 0.22161272168159485\n",
      "Epoch 83 completed.\n",
      "Loss: 0.2185290902853012\n",
      "Epoch 84 completed.\n",
      "Loss: 0.21553562581539154\n",
      "Epoch 85 completed.\n",
      "Loss: 0.21262452006340027\n",
      "Epoch 86 completed.\n",
      "Loss: 0.20979410409927368\n",
      "Epoch 87 completed.\n",
      "Loss: 0.20704607665538788\n",
      "Epoch 88 completed.\n",
      "Loss: 0.20437917113304138\n",
      "Epoch 89 completed.\n",
      "Loss: 0.20179179310798645\n",
      "Epoch 90 completed.\n",
      "Loss: 0.19928136467933655\n",
      "Epoch 91 completed.\n",
      "Loss: 0.1968439817428589\n",
      "Epoch 92 completed.\n",
      "Loss: 0.19447986781597137\n",
      "Epoch 93 completed.\n",
      "Loss: 0.19218479096889496\n",
      "Epoch 94 completed.\n",
      "Loss: 0.1899522840976715\n",
      "Epoch 95 completed.\n",
      "Loss: 0.18777954578399658\n",
      "Epoch 96 completed.\n",
      "Loss: 0.18566405773162842\n",
      "Epoch 97 completed.\n",
      "Loss: 0.18360544741153717\n",
      "Epoch 98 completed.\n",
      "Loss: 0.18160149455070496\n",
      "Epoch 99 completed.\n",
      "Loss: 0.17964746057987213\n",
      "Epoch 100 completed.\n",
      "Loss: 0.17774231731891632\n",
      "Epoch 101 completed.\n",
      "Loss: 0.1758846640586853\n",
      "Epoch 102 completed.\n",
      "Loss: 0.17407430708408356\n",
      "Epoch 103 completed.\n",
      "Loss: 0.17230801284313202\n",
      "Epoch 104 completed.\n",
      "Loss: 0.1705850511789322\n",
      "Epoch 105 completed.\n",
      "Loss: 0.16890104115009308\n",
      "Epoch 106 completed.\n",
      "Loss: 0.16725656390190125\n",
      "Epoch 107 completed.\n",
      "Loss: 0.16565287113189697\n",
      "Epoch 108 completed.\n",
      "Loss: 0.16408690810203552\n",
      "Epoch 109 completed.\n",
      "Loss: 0.16255542635917664\n",
      "Epoch 110 completed.\n",
      "Loss: 0.16105826199054718\n",
      "Epoch 111 completed.\n",
      "Loss: 0.15959565341472626\n",
      "Epoch 112 completed.\n",
      "Loss: 0.1581655740737915\n",
      "Epoch 113 completed.\n",
      "Loss: 0.15676476061344147\n",
      "Epoch 114 completed.\n",
      "Loss: 0.15539218485355377\n",
      "Epoch 115 completed.\n",
      "Loss: 0.1540469527244568\n",
      "Epoch 116 completed.\n",
      "Loss: 0.15272937715053558\n",
      "Epoch 117 completed.\n",
      "Loss: 0.15143945813179016\n",
      "Epoch 118 completed.\n",
      "Loss: 0.15017645061016083\n",
      "Epoch 119 completed.\n",
      "Loss: 0.1489395946264267\n",
      "Epoch 120 completed.\n",
      "Loss: 0.14772619307041168\n",
      "Epoch 121 completed.\n",
      "Loss: 0.1465338170528412\n",
      "Epoch 122 completed.\n",
      "Loss: 0.14536438882350922\n",
      "Epoch 123 completed.\n",
      "Loss: 0.14421820640563965\n",
      "Epoch 124 completed.\n",
      "Loss: 0.14309503138065338\n",
      "Epoch 125 completed.\n",
      "Loss: 0.14199256896972656\n",
      "Epoch 126 completed.\n",
      "Loss: 0.14091043174266815\n",
      "Epoch 127 completed.\n",
      "Loss: 0.13984699547290802\n",
      "Epoch 128 completed.\n",
      "Loss: 0.13880227506160736\n",
      "Epoch 129 completed.\n",
      "Loss: 0.13777528703212738\n",
      "Epoch 130 completed.\n",
      "Loss: 0.1367657482624054\n",
      "Epoch 131 completed.\n",
      "Loss: 0.13577421009540558\n",
      "Epoch 132 completed.\n",
      "Loss: 0.13480089604854584\n",
      "Epoch 133 completed.\n",
      "Loss: 0.13384531438350677\n",
      "Epoch 134 completed.\n",
      "Loss: 0.13290530443191528\n",
      "Epoch 135 completed.\n",
      "Loss: 0.13198044896125793\n",
      "Epoch 136 completed.\n",
      "Loss: 0.1310703158378601\n",
      "Epoch 137 completed.\n",
      "Loss: 0.1301753669977188\n",
      "Epoch 138 completed.\n",
      "Loss: 0.129294753074646\n",
      "Epoch 139 completed.\n",
      "Loss: 0.12842780351638794\n",
      "Epoch 140 completed.\n",
      "Loss: 0.12757466733455658\n",
      "Epoch 141 completed.\n",
      "Loss: 0.12673409283161163\n",
      "Epoch 142 completed.\n",
      "Loss: 0.12590603530406952\n",
      "Epoch 143 completed.\n",
      "Loss: 0.12509174644947052\n",
      "Epoch 144 completed.\n",
      "Loss: 0.12429028004407883\n",
      "Epoch 145 completed.\n",
      "Loss: 0.1235015019774437\n",
      "Epoch 146 completed.\n",
      "Loss: 0.12272506952285767\n",
      "Epoch 147 completed.\n",
      "Loss: 0.12196019291877747\n",
      "Epoch 148 completed.\n",
      "Loss: 0.1212058961391449\n",
      "Epoch 149 completed.\n",
      "Loss: 0.12046293169260025\n",
      "Epoch 150 completed.\n",
      "Loss: 0.11973121762275696\n",
      "Epoch 151 completed.\n",
      "Loss: 0.11900994926691055\n",
      "Epoch 152 completed.\n",
      "Loss: 0.11829998344182968\n",
      "Epoch 153 completed.\n",
      "Loss: 0.11759961396455765\n",
      "Epoch 154 completed.\n",
      "Loss: 0.11690893024206161\n",
      "Epoch 155 completed.\n",
      "Loss: 0.11622797697782516\n",
      "Epoch 156 completed.\n",
      "Loss: 0.11555640399456024\n",
      "Epoch 157 completed.\n",
      "Loss: 0.11489397287368774\n",
      "Epoch 158 completed.\n",
      "Loss: 0.11424180120229721\n",
      "Epoch 159 completed.\n",
      "Loss: 0.11359853297472\n",
      "Epoch 160 completed.\n",
      "Loss: 0.1129632219672203\n",
      "Epoch 161 completed.\n",
      "Loss: 0.11233669519424438\n",
      "Epoch 162 completed.\n",
      "Loss: 0.11171896755695343\n",
      "Epoch 163 completed.\n",
      "Loss: 0.11110956221818924\n",
      "Epoch 164 completed.\n",
      "Loss: 0.1105082631111145\n",
      "Epoch 165 completed.\n",
      "Loss: 0.10991466045379639\n",
      "Epoch 166 completed.\n",
      "Loss: 0.10932931303977966\n",
      "Epoch 167 completed.\n",
      "Loss: 0.10875119268894196\n",
      "Epoch 168 completed.\n",
      "Loss: 0.10818102210760117\n",
      "Epoch 169 completed.\n",
      "Loss: 0.10761800408363342\n",
      "Epoch 170 completed.\n",
      "Loss: 0.10706156492233276\n",
      "Epoch 171 completed.\n",
      "Loss: 0.10651257634162903\n",
      "Epoch 172 completed.\n",
      "Loss: 0.10597045719623566\n",
      "Epoch 173 completed.\n",
      "Loss: 0.1054348424077034\n",
      "Epoch 174 completed.\n",
      "Loss: 0.10490645468235016\n",
      "Epoch 175 completed.\n",
      "Loss: 0.1043848842382431\n",
      "Epoch 176 completed.\n",
      "Loss: 0.10386953502893448\n",
      "Epoch 177 completed.\n",
      "Loss: 0.103360116481781\n",
      "Epoch 178 completed.\n",
      "Loss: 0.10285647958517075\n",
      "Epoch 179 completed.\n",
      "Loss: 0.10235916078090668\n",
      "Epoch 180 completed.\n",
      "Loss: 0.10186823457479477\n",
      "Epoch 181 completed.\n",
      "Loss: 0.10138317197561264\n",
      "Epoch 182 completed.\n",
      "Loss: 0.10090316832065582\n",
      "Epoch 183 completed.\n",
      "Loss: 0.10042891651391983\n",
      "Epoch 184 completed.\n",
      "Loss: 0.09996034950017929\n",
      "Epoch 185 completed.\n",
      "Loss: 0.0994972512125969\n",
      "Epoch 186 completed.\n",
      "Loss: 0.0990399569272995\n",
      "Epoch 187 completed.\n",
      "Loss: 0.09858749806880951\n",
      "Epoch 188 completed.\n",
      "Loss: 0.09814009815454483\n",
      "Epoch 189 completed.\n",
      "Loss: 0.09769795835018158\n",
      "Epoch 190 completed.\n",
      "Loss: 0.09726071357727051\n",
      "Epoch 191 completed.\n",
      "Loss: 0.09682849794626236\n",
      "Epoch 192 completed.\n",
      "Loss: 0.09640088677406311\n",
      "Epoch 193 completed.\n",
      "Loss: 0.0959782600402832\n",
      "Epoch 194 completed.\n",
      "Loss: 0.09555988758802414\n",
      "Epoch 195 completed.\n",
      "Loss: 0.09514664858579636\n",
      "Epoch 196 completed.\n",
      "Loss: 0.0947377160191536\n",
      "Epoch 197 completed.\n",
      "Loss: 0.09433292597532272\n",
      "Epoch 198 completed.\n",
      "Loss: 0.09393298625946045\n",
      "Epoch 199 completed.\n",
      "Loss: 0.09353700280189514\n",
      "Epoch 200 completed.\n",
      "Loss: 0.09314548969268799\n",
      "GraphSAGE Accuracy: 0.5074\n",
      "{'GCN': 0.5009048136083967, 'GAT': 0.5085052479189287, 'GraphSAGE': 0.5074194715888527}\n",
      "\n",
      "Among the three models, GAT achieved the highest accuracy of 0.5085.\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"GCN\": GCN(num_node_features=data.num_features, hidden_channels=64),\n",
    "    \"GAT\": GAT(num_node_features=data.num_features, hidden_channels=64),\n",
    "    \"GraphSAGE\": GraphSAGE(num_node_features=data.num_features, hidden_channels=64),\n",
    "}\n",
    "\n",
    "# Optimizers\n",
    "optimizers = {\n",
    "    \"GCN\": torch.optim.Adam(models[\"GCN\"].parameters(), lr=0.01, weight_decay=5e-4),\n",
    "    \"GAT\": torch.optim.Adam(models[\"GAT\"].parameters(), lr=0.01, weight_decay=5e-4),\n",
    "    \"GraphSAGE\": torch.optim.Adam(models[\"GraphSAGE\"].parameters(), lr=0.01, weight_decay=5e-4),\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "accuracies = {}\n",
    "for model_name, model in models.items():\n",
    "    optimizer = optimizers[model_name]\n",
    "    acc = train_and_evaluate(model, data, optimizer)\n",
    "    accuracies[model_name] = acc\n",
    "    print(f'{model_name} Accuracy: {acc:.4f}')\n",
    "\n",
    "print(accuracies)\n",
    "# Simple Text Analysis\n",
    "best_model = max(accuracies, key=accuracies.get)\n",
    "print(f'\\nAmong the three models, {best_model} achieved the highest accuracy of {accuracies[best_model]:.4f}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUTPUT:\n",
    "\n",
    "    Government:\n",
    "        GCN Accuracy: 0.5041\n",
    "        GAT Accuracy: 0.4996\n",
    "        GraphSAGE Accuracy: 0.5232\n",
    "\n",
    "    New Sites:\n",
    "        GCN Accuracy: 0.4965\n",
    "        GAT Accuracy: 0.4891\n",
    "        GraphSAGE Accuracy: Kernel Died\n",
    "\n",
    "    Athletes:\n",
    "        GCN Accuracy: 0.5169\n",
    "        GAT Accuracy: 0.5080\n",
    "        GraphSAGE Accuracy: 0.4994\n",
    "\n",
    "    Public Figures:\n",
    "        GCN Accuracy: 0.5036\n",
    "        GAT Accuracy: 0.4981\n",
    "        GraphSAGE Accuracy: 0.5139\n",
    "\n",
    "    TV Shows:\n",
    "        GCN Accuracy: 0.5143\n",
    "        GAT Accuracy: 0.5197\n",
    "        GraphSAGE Accuracy: 0.4980\n",
    "\n",
    "    Politician:\n",
    "        GCN Accuracy: 0.5000\n",
    "        GAT Accuracy: 0.5153\n",
    "        GraphSAGE Accuracy: 0.4974\n",
    "\n",
    "    Artist:\n",
    "        GCN Accuracy: 0.5035\n",
    "        GAT Accuracy: 0.4928\n",
    "        GraphSAGE Accuracy: Kernel Died\n",
    "\n",
    "    Company:\n",
    "        GCN Accuracy: 0.5009\n",
    "        GAT Accuracy: 0.5085\n",
    "        GraphSAGE Accuracy: 0.5074\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def community_detection(embeddings, n_clusters=5):\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    clusters = kmeans.fit_predict(embeddings.detach().numpy())\n",
    "    return clusters\n",
    "\n",
    "embeddings = model(data)\n",
    "clusters = community_detection(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_communities(G, clusters):\n",
    "    plt.figure(figsize=(20, 20))  # Large figure size for clarity\n",
    "    \n",
    "    # Use a layout that spreads nodes out more\n",
    "    pos = nx.spring_layout(G, k=0.05, iterations=300)  # Increase k to spread out nodes more\n",
    "\n",
    "    # Draw nodes with community clusters\n",
    "    nodes = nx.draw_networkx_nodes(G, pos, node_color=clusters, cmap=plt.cm.rainbow, \n",
    "                                   node_size=50, alpha=0.9)\n",
    "    \n",
    "    # Draw edges with reduced opacity and thickness\n",
    "    edges = nx.draw_networkx_edges(G, pos, alpha=0.3, width=0.2)\n",
    "    \n",
    "    # Draw node labels if the graph is not too dense\n",
    "    # nx.draw_networkx_labels(G, pos, font_size=8, font_color='black')\n",
    "    \n",
    "    plt.axis('off')  # Turn off the axis\n",
    "    plt.tight_layout()  # Fit the plot nicely into the figure\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "visualize_communities(G, clusters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
